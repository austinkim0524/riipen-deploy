{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# I saved all PDF files under the PDF folder in my env directory\n",
    "pdf_docs_path = os.path.join(\"PDF\")\n",
    "one_pdf_path = os.path.join(pdf_docs_path,\"Protect_Your_Home_From_Flooding_Brochure.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file has 6 pages.\n"
     ]
    }
   ],
   "source": [
    "# Trying a better result with pdftotext\n",
    "import pdftotext\n",
    "\n",
    "with open(one_pdf_path, \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)\n",
    "    \n",
    "print(\"This file has\", len(pdf), \"pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can get rid of new lines and stray spaces\n",
    "\n",
    "import re\n",
    "cleanerPDF = re.sub('\\s+', ' ', pdf[2]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docText = \"\"\n",
    "for page in pdf:\n",
    "    docText = docText + re.sub('\\s+', ' ', page).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "df = pd.DataFrame(columns=['Imperative Sentences'])\n",
    "\n",
    "impSents = list()\n",
    "docSent = sent_tokenize(docText)\n",
    "for sentence in docSent:\n",
    "    text = word_tokenize(sentence)\n",
    "    extractPOS = nltk.pos_tag(text)\n",
    "    # Verb, base or gerund tense\n",
    "    if extractPOS[0][1] == 'VB' or extractPOS[0][1] == 'VBG':\n",
    "        impSents.append(sentence)\n",
    "\n",
    "# Populate the freaking dataframe        \n",
    "df['Imperative Sentences']=impSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imperative Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Protect Your Home from Flooding LOW-COST PROJE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Insure Your Property.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Reduce Your Risk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Decide how to prepare your family and protect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Consider which of the methods included in this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Depending on the project, you may need to cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Consulting adjacent property owners is very im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>conditioning condensers, heat pumps, water met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Retaining and creating people, property, and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Consider options such as rain gardens, food el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Be sure to choose a device with battery-operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Increase the height of electric the ground level.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Consider raising other major appliances, • Dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Contact your local community offcials.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Visit the following websites: FEMA, Protect Yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Imperative Sentences\n",
       "0   Protect Your Home from Flooding LOW-COST PROJE...\n",
       "1                               Insure Your Property.\n",
       "2                                   Reduce Your Risk.\n",
       "3   Decide how to prepare your family and protect ...\n",
       "4   Consider which of the methods included in this...\n",
       "5   Depending on the project, you may need to cons...\n",
       "6   Consulting adjacent property owners is very im...\n",
       "7   conditioning condensers, heat pumps, water met...\n",
       "8   Retaining and creating people, property, and t...\n",
       "9   Consider options such as rain gardens, food el...\n",
       "10  Be sure to choose a device with battery-operat...\n",
       "11  Increase the height of electric the ground level.\n",
       "12  Consider raising other major appliances, • Dep...\n",
       "13             Contact your local community offcials.\n",
       "14  Visit the following websites: FEMA, Protect Yo..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('www.fema.gov/media-library/assets/documents/13261', 'NN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "Canada Canada PROPN NNP pobj Xxxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "Ontario Ontario PROPN NNP pobj Xxxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "Toronto Toronto PROPN NNP pobj Xxxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "Oakville Oakville PROPN NNP pobj Xxxxx True False\n",
      "in in ADP IN prep xx True True\n",
      "Ottawa Ottawa PROPN NNP pobj Xxxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "Last extracted token: .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion in Canada in Ontario in Toronto in Oakville in Ottawa.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)\n",
    "\n",
    "print(\"Last extracted token:\",doc[len(doc)-1].shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.K. 27 31 GPE\n",
      "Canada 58 64 GPE\n",
      "Ontario 68 75 GPE\n",
      "Toronto 79 86 GPE\n",
      "Oakville 90 98 GPE\n",
      "Ottawa 102 108 GPE\n"
     ]
    }
   ],
   "source": [
    "# Geopolitical entry\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"GPE\":\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close VERB VB\n",
      "the DET DT\n",
      "door NOUN NN\n",
      "in ADP IN\n",
      "case NOUN NN\n",
      "of ADP IN\n",
      "fire NOUN NN\n",
      ". PUNCT .\n",
      "Close ADV RB\n",
      "to ADP IN\n",
      "the DET DT\n",
      "door NOUN NN\n",
      ", PUNCT ,\n",
      "it PRON PRP\n",
      "may VERB MD\n",
      "be AUX VB\n",
      "hot ADJ JJ\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Close the door in case of fire. Close to the door, it may be hot.\")\n",
    "for word in doc:\n",
    "    print (word, word.pos_, word.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close the door in case of fire.\n",
      "Close to the door, it may be hot.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print (sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close RB\n",
      "the DT\n",
      "door NN\n",
      "in IN\n",
      "case NN\n",
      "of IN\n",
      "fire NN\n",
      ". .\n",
      "Close RB\n",
      "to TO\n",
      "the DT\n",
      "door NN\n",
      ", ,\n",
      "it PRP\n",
      "may MD\n",
      "be VB\n",
      "hot JJ\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# Just a comparison using NLTK\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "docText = \"Close the door in case of fire. Close to the door, it may be hot.\"\n",
    "docSent = sent_tokenize(docText)\n",
    "for sentence in docSent:\n",
    "    text = word_tokenize(sentence)\n",
    "    extractPOS = nltk.pos_tag(text)\n",
    "    for word in extractPOS:\n",
    "        print (word[0],word[1])\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Close', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('door', 'NN'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('hot', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close the door in case of fire.\n"
     ]
    }
   ],
   "source": [
    "# Imperative sentence extractor with Spacy\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df = pd.DataFrame(columns=['Imperative Sentences'])\n",
    "doc = nlp(docText)\n",
    "\n",
    "impSents = list()\n",
    "for sentence in doc.sents:\n",
    "    if sentence[0].pos_=='VERB' and (sentence[0].tag_==\"VB\" or sentence[0].tag_==\"VBG\"):\n",
    "        impSents.append(sentence)\n",
    "\n",
    "# Populate the freaking dataframe        \n",
    "df['Imperative Sentences']=impSents\n",
    "for item in df['Imperative Sentences']:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
