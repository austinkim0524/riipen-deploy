{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file that was tagged by all of us\n",
    "df = pd.read_csv(\"./datasets/text_data.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'File', 'Page', 'Text', 'Context', 'Unnamed: 5', 'Unnamed: 6'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cover page', 'Carbon Neutrality', 'Climate change adaptation',\n",
       "       'Undefined', 'Acknowledgments', 'Contents', 'Bibliography',\n",
       "       'Glossary', 'Appendix', 'Flooding', 'General', 'Storm',\n",
       "       'ice storm', 'Wildfire', 'Mitigation', 'Heat wave',\n",
       "       'Climate model', 'glossary', 'bibliography', 'Wind Storm',\n",
       "       'drought', 'cover page', nan], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many context \n",
    "df['Context'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract rows only from appropriate context\n",
    "# only include climate related context\n",
    "df2=df[df['Context'].isin(['Carbon Neutrality', 'Climate change adaptation','Flooding', 'General', 'Storm',\n",
    "       'ice storm', 'Wildfire', 'Mitigation',  'Heat wave',\n",
    "       'Wind Storm', 'drought'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context\n",
       "Carbon Neutrality             10\n",
       "Climate change adaptation    708\n",
       "Flooding                     282\n",
       "General                       51\n",
       "Heat wave                      5\n",
       "Mitigation                    20\n",
       "Storm                          9\n",
       "Wildfire                      21\n",
       "Wind Storm                    13\n",
       "drought                        1\n",
       "ice storm                     14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many records per climate related context\n",
    "df2.groupby(['Context']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Context\n",
       "Carbon Neutrality             10\n",
       "Climate change adaptation    708\n",
       "Flooding                     282\n",
       "General                       51\n",
       "Heat wave                      6\n",
       "Mitigation                    20\n",
       "Storm                         36\n",
       "Wildfire                      21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not enough data to classify anything other than 'Climate change adaptation' and \"Flooding\"\n",
    "# lets train a classify for each context\n",
    "# Merge Storm, ice storm and Wind Storm as one context\n",
    "# also merge drought and Heat Wave as one context\n",
    "df2.loc[df2['Context'].isin(['Wind Storm','ice storm']),'Context']='Storm'\n",
    "df2.loc[df2['Context']=='drought','Context']='Heat wave'\n",
    "df2.groupby(['Context']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to use bag of words approach \n",
    "# use count vectorizer\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1134, step=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test data set use stratified sampling\n",
    "x_train, x_test, y_train, y_test = train_test_split(df2['Text'], df2['Context'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reset_index(drop=True,inplace=True)\n",
    "x_test.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context\n",
       "Carbon Neutrality              7\n",
       "Climate change adaptation    495\n",
       "Flooding                     196\n",
       "General                       35\n",
       "Heat wave                      6\n",
       "Mitigation                    17\n",
       "Storm                         28\n",
       "Wildfire                       9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure y_train contains all the Context\n",
    "(y_train.to_frame()).groupby(['Context']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context\n",
       "Carbon Neutrality              3\n",
       "Climate change adaptation    213\n",
       "Flooding                      86\n",
       "General                       16\n",
       "Mitigation                     3\n",
       "Storm                          8\n",
       "Wildfire                      12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure y_test contains all the Context\n",
    "(y_test.to_frame()).groupby(['Context']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model using multinomial classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline_nb = Pipeline([\n",
    "    ('bow', LemmaCountVectorizer(analyzer='word', stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 LemmaCountVectorizer(analyzer='word', binary=False,\n",
       "                                      decode_error='strict',\n",
       "                                      dtype=<class 'numpy.int64'>,\n",
       "                                      encoding='utf-8', input='content',\n",
       "                                      lowercase=True, max_df=1.0,\n",
       "                                      max_features=None, min_df=1,\n",
       "                                      ngram_range=(1, 1), preprocessor=None,\n",
       "                                      stop_words='english', strip_accents=None,\n",
       "                                      token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                      tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb=pipeline_nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Carbon Neutrality       0.00      0.00      0.00         0\n",
      "Climate change adaptation       1.00      0.71      0.83       308\n",
      "                 Flooding       0.37      0.88      0.52        33\n",
      "                  General       0.00      0.00      0.00         0\n",
      "                Heat wave       0.00      0.00      0.00         0\n",
      "               Mitigation       0.00      0.00      0.00         0\n",
      "                    Storm       0.00      0.00      0.00         0\n",
      "                 Wildfire       0.00      0.00      0.00         0\n",
      "\n",
      "                 accuracy                           0.72       341\n",
      "                macro avg       0.17      0.20      0.17       341\n",
      "             weighted avg       0.94      0.72      0.80       341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# the f1-score is not that good\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(pred_nb, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGD Classifier\n",
    "pipeline_sga = Pipeline([\n",
    "    ('bow', LemmaCountVectorizer(analyzer='word', stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Carbon Neutrality       1.00      1.00      1.00         3\n",
      "Climate change adaptation       0.96      0.88      0.92       232\n",
      "                 Flooding       0.84      0.87      0.85        83\n",
      "                  General       0.25      0.67      0.36         6\n",
      "               Mitigation       0.00      0.00      0.00         1\n",
      "                    Storm       0.88      0.78      0.82         9\n",
      "                 Wildfire       0.58      1.00      0.74         7\n",
      "\n",
      "                 accuracy                           0.87       341\n",
      "                macro avg       0.64      0.74      0.67       341\n",
      "             weighted avg       0.91      0.87      0.89       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# f1-score actually slightly better than Multinomial\n",
    "pipeline_sga.fit(x_train,y_train)\n",
    "pred_sga=pipeline_sga.predict(x_test)\n",
    "print (classification_report(pred_sga, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use random forest\n",
    "# f1-score is actually worse than SGD Classifier\n",
    "pipeline_rf = Pipeline([\n",
    "    ('bow', LemmaCountVectorizer(analyzer='word', stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Carbon Neutrality       0.00      0.00      0.00         0\n",
      "Climate change adaptation       0.98      0.81      0.89       263\n",
      "                 Flooding       0.76      0.81      0.78        74\n",
      "                  General       0.00      0.00      0.00         1\n",
      "                Heat wave       0.00      0.00      0.00         0\n",
      "               Mitigation       0.00      0.00      0.00         0\n",
      "                    Storm       0.30      1.00      0.46         3\n",
      "                 Wildfire       0.00      0.00      0.00         0\n",
      "\n",
      "                 accuracy                           0.81       341\n",
      "                macro avg       0.26      0.33      0.27       341\n",
      "             weighted avg       0.92      0.81      0.86       341\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf.fit(x_train,y_train)\n",
    "pred_rf=pipeline_rf.predict(x_test)\n",
    "print (classification_report(pred_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression\n",
    "pipeline_lr = Pipeline([\n",
    "    ('bow', LemmaCountVectorizer(analyzer='word', stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "        Carbon Neutrality       0.00      0.00      0.00         0\n",
      "Climate change adaptation       0.98      0.81      0.89       263\n",
      "                 Flooding       0.76      0.81      0.78        74\n",
      "                  General       0.00      0.00      0.00         1\n",
      "                Heat wave       0.00      0.00      0.00         0\n",
      "               Mitigation       0.00      0.00      0.00         0\n",
      "                    Storm       0.30      1.00      0.46         3\n",
      "                 Wildfire       0.00      0.00      0.00         0\n",
      "\n",
      "                 accuracy                           0.81       341\n",
      "                macro avg       0.26      0.33      0.27       341\n",
      "             weighted avg       0.92      0.81      0.86       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_lr.fit(x_train,y_train)\n",
    "pred_lr=pipeline_rf.predict(x_test)\n",
    "print (classification_report(pred_lr, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
